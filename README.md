SYNOPSIS SYNOPSIS 
The project entitled ‘AI Enable Assistant For Visually Impaired‘ proposes a comprehensive blind assistance system that harnesses the capabilities of three crucial image processing technologies: Face recognition, Object detection, and Optical Character Recognition (OCR). An estimated 39 million people around the world are completely blind. Advancements in image processing and machine learning have led to innovative solutions to address vision impairment challenges. This work enables blind individuals to navigate independently by converting visual information into audio cues, including object detection and OCR text reading.  The system will identify people, objects, and text in the user's surroundings, providing auditory information to enhance spatial awareness. 
The face recognition component of the system aims to provide visually impaired individuals with the ability to recognize and interact with people in their environment. The object detection module focuses on enhancing spatial awareness by identifying and describing objects in the user’s surroundings. The OCR component extends the system's functionality to text recognition. 
This project extensively utilizes machine learning models, particularly deep learning techniques, to enhance accuracy and efficiency. By combining face recognition, object detection, and OCR, the system empowers visually impaired individuals to navigate their surroundings more effectively, engage in social interactions with greater confidence, and access printed information independently. The integration of pre-trained deep learning models allows the system to continuously improve and adapt, ensuring a more reliable user experience. 
We use Raspberry Pi for image detection, and the information about it is received by the blind individuals through an earphone. Raspberry Pi is used by installing it on things like glasses, caps, etc., thus making it very user-friendly for a blind individual. Raspberry Pi is a credit cardsized single-board computer aimed at making computing and digital creation accessible to people of all ages, often used for educational purposes and prototyping due to its affordability, modularity, and extensive community support. Here we use the Raspberry Pi 4 processor with a pre-trained Convolutional Neural Network (CNN) model using TensorFlow, connected to a Noir camera that captures real-time images, which are processed by the Raspberry Pi using Python and the COCO model to detect and classify objects. Detected objects are marked with boundary boxes, and their category indices are stored in a text file. This text is then converted to speech using eSpeak. Machine learning-based models, such as CNNs, play a crucial role accurately recognizing and classifying objects, making real-time navigation more efficient. 
This portable device is installed on a blind stick or other accessories, making it easy for users to carry. 
The system will be implemented using Python 3, Anaconda Navigator, and Spyder IDE. The project will help visually impaired people and the blind to navigate freely by experiencing their surroundings. The objective of the proposed work is to change the visual world into an audio world by notifying blind people. 
